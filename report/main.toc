\babel@toc {french}{}\relax 
\contentsline {chapter}{\numberline {1}Linear and Weighted Ridge Regression}{2}{chapter.1}%
\contentsline {section}{\numberline {1.1}Data Matrix with Bias Term}{2}{section.1.1}%
\contentsline {section}{\numberline {1.2}Linear Regression Optimization}{2}{section.1.2}%
\contentsline {section}{\numberline {1.3}Ridge Regression Optimization}{2}{section.1.3}%
\contentsline {section}{\numberline {1.4}Weighted Ridge Regression}{2}{section.1.4}%
\contentsline {section}{\numberline {1.5}Root Mean Square Error Implementation}{2}{section.1.5}%
\contentsline {chapter}{\numberline {2}Cross-Validation Techniques}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}K-Fold Cross-Validation Splitter}{3}{section.2.1}%
\contentsline {section}{\numberline {2.2}Cross-Validation for Ridge Regression}{3}{section.2.2}%
\contentsline {section}{\numberline {2.3}Hyperparameter Selection}{3}{section.2.3}%
\contentsline {chapter}{\numberline {3}Gradient Descent for Ridge Regression}{4}{chapter.3}%
\contentsline {section}{\numberline {3.1}Ridge Regression Gradient Computation}{4}{section.3.1}%
\contentsline {section}{\numberline {3.2}Learning Rate Schedules}{4}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Exponential Decay}{4}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Cosine Annealing}{4}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}Gradient Descent Step Implementation}{4}{section.3.3}%
\contentsline {section}{\numberline {3.4}Gradient Descent with Different Learning Rates}{4}{section.3.4}%
\contentsline {chapter}{\numberline {4}Results and Analysis}{5}{chapter.4}%
\contentsline {section}{\numberline {4.1}Performance Comparison}{5}{section.4.1}%
\contentsline {section}{\numberline {4.2}Regression Comparison Visualization}{5}{section.4.2}%
\contentsline {section}{\numberline {4.3}Discussion and Conclusions}{5}{section.4.3}%
